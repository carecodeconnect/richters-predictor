{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../submissions')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from utils import load_train_data, load_test_data\n",
    "from evaluate import evaluate_model\n",
    "from utils import save_submission, save_model, load_model\n",
    "from encoding import freq_encode, get_house_volume\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder, FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_train_data(local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for preprocessing and modelling\n",
    "TARGET = 'damage_grade'\n",
    "\n",
    "X = train_data.copy()\n",
    "y = train_data.pop(TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,\n",
    "                                                      stratify=y,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', predictor=None, ...):\n",
      "F1-score (validation): 0.745\n",
      "F1-score (training): 0.765\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First we run an XGB Classifier with default parameters\n",
    "\n",
    "base_line_pipeline = load_model('../models/model_baseline.pickle')\n",
    "\n",
    "y_train_ = y_train.copy()\n",
    "y_valid_ = y_valid.copy()\n",
    "\n",
    "\n",
    "new_model = XGBClassifier()\n",
    "\n",
    "new_pipeline = base_line_pipeline.set_params(model=new_model)\n",
    "\n",
    "# Evaluate model performance\n",
    "if \"xgboost\" in str(type(new_model)):\n",
    "    y_train_ = y_train_.apply(lambda x: int(x-1))\n",
    "    y_valid_ = y_valid_.apply(lambda x: int(x-1))\n",
    "\n",
    "\n",
    "score_valid, score_train = evaluate_model(new_pipeline, X_train, X_valid, y_train_, y_valid_)\n",
    "print(f\"{new_model}:\")\n",
    "print(f\"F1-score (validation): {score_valid :.3f}\")\n",
    "print(f\"F1-score (training): {score_train :.3f}\")\n",
    "print(\"________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# Define sample space for hyperparameter search \n",
    "\n",
    "space={'max_depth': hp.randint(\"max_depth\", 3, 18),\n",
    "        'gamma': hp.uniform ('gamma', 1, 9),\n",
    "        'reg_alpha' : hp.randint('reg_alpha', 40,180),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        'min_child_weight' : hp.randint('min_child_weight', 0, 10),\n",
    "        'n_estimators': hp.randint('n_estimators', 50, 200),\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective of search: Important is the \"loos\" feature\n",
    "def objective(space):\n",
    "    new_model=XGBClassifier(seed=space['seed'],\n",
    "                    max_depth = space['max_depth'],\n",
    "                    gamma = space['gamma'],\n",
    "                    reg_alpha = space['reg_alpha'], \n",
    "                    reg_lambda = space['reg_lambda'],\n",
    "                    colsample_bytree = space['colsample_bytree'],\n",
    "                    min_child_weight = space['min_child_weight'],\n",
    "                    n_estimators = space['n_estimators'], \n",
    ")\n",
    "    \n",
    "    clf = base_line_pipeline.set_params(model=new_model)\n",
    "    \n",
    "    score_valid, score_train = evaluate_model(clf, X_train, X_valid, y_train_, y_valid_)\n",
    "\n",
    "    return {'loss': 1-score_valid, 'status': STATUS_OK }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:39<00:00, 39.52s/trial, best loss: 0.25743941981159224]\n"
     ]
    }
   ],
   "source": [
    "# Perform hyerparam search\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 10,\n",
    "                        trials = trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model for best parameters\n",
    "new_model = XGBClassifier(**best_hyperparams)\n",
    "clf = base_line_pipeline.set_params(model=new_model)\n",
    "\n",
    "score_valid, score_training = evaluate_model(clf, X_train, X_valid, y_train_, y_valid_)\n",
    "\n",
    "print(f\"F1-score (validation): {score_valid :.3f}\")\n",
    "print(f\"F1-score (training): {score_training :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and save predictions into a file for submission\n",
    "test_data = load_test_data(local=True)\n",
    "\n",
    "# Create timestemp for filenames of model and submission files\n",
    "timestamp =  datetime.now().timestamp()\n",
    "\n",
    "# Save submission file\n",
    "submission_fpath = save_submission(clf, test_data, timestamp)\n",
    "\n",
    "# Save model\n",
    "model_fpath = save_model(clf, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
